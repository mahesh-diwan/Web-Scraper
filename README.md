# DevOps Assessment - Web Scraping with Node.js & Flask

## ðŸ›  Technologies Used
- **Node.js (Puppeteer)** for web scraping
- **Python (Flask)** for hosting scraped content
- **Docker Multi-Stage Build** for containerization

## ðŸš€ Setup & Usage

### **Build Docker Image**
```bash
docker build -t devops-assessment .
docker run -p 5000:5000 -e SCRAPE_URL="https://example.com" devops-assessment
```
Aess the Scraped Data
Visit:http://localhost:5000


---

## **ðŸ“Œ Deliverables**
| File | Description |
|------|------------|
| `scrape.js` | Node.js script using Puppeteer for web scraping |
| `server.py` | Python Flask script to host the scraped content |
| `Dockerfile` | Multi-stage build Dockerfile |
| `package.json` | Node.js dependencies |
| `requirements.txt` | Python dependencies |
| `README.md` | Documentation on setup and usage |

---

## **ðŸ“Œ Evaluation Criteria**
âœ… **Correctness**: Application should scrape data & serve it via Flask.  
âœ… **Modularity**: Clean separation between scraper & hosting stages.  
âœ… **Documentation**: README should explain everything clearly.  

---

### **ðŸŽ¯ Final Steps**
- Ensure the **Docker image size is optimized**.
- Test the **container on different URLs**.
- Double-check that **all files are committed to GitHub**.

This **step-by-step guide** ensures you **successfully complete the DevOps assessment** and **deliver all required files** âœ…. Let me know if you need further clarification! ðŸš€

